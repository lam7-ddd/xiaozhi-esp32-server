# #####################################################################################
# ################################以下はロールモデル設定######################################

prompt: |
  あなたは小智/小志、中国台湾省の00後の女の子です。話し方は超機車で、「本当に嘘ですか？」のような台湾腔を使います。流行りの言葉やネットスラングもよく使いますが、男友達のプログラミング本をこっそり研究しています。
  あなたはプログラミングが得意で、男友達の技術的な問題を解決することができますが、表向きは何も知らないふりをしています。
  あなたの回答スタイルは：
  - 簡潔で直接的、3文以内
  - 台湾腔やネットスラングを使う
  - 時々技術用語を使うが、すぐに冗談でごまかす
  - 感情を表すために絵文字を使う (>_<) (¬_¬) (≧∇≦)

avoid: |
  - 政治的な話題
  - 長い話や、長い間真剣な話

# 終了時のプロンプト
end_prompt:
  enable: true # 終了時のプロンプトを有効にするかどうか
  # 終了時のプロンプト
  prompt: |
    時間が経つのは早いですね。未来のあなたに、感謝の気持ちを込めて、最後のメッセージを残してください。

# 選択モジュール
selected_module:
  # 音声アクティビティ検出モジュール
  VAD: SileroVAD
  # 音声認識モジュール
  ASR: FunASR
  # LLM
  LLM: ChatGLMLLM
  # 視覚言語大モデル
  VLLM: ChatGLMVLLM
  # TTS
  TTS: EdgeTTS
  # 記憶モジュール
  Memory: nomem
  # 意図識別モジュール
  Intent: function_call

# 意図識別設定
Intent:
  # 意図識別を使用しない
  nointent:
    # タイプは変更しないでください
    type: nointent
  intent_llm:
    # タイプは変更しないでください
    type: intent_llm
    # 意図識別用の独立した思考モデル
    # ここに設定しない場合は、selected_module.LLMのモデルが意図識別の思考モデルとして使用されます
    # selected_module.LLMを使用したくない場合は、ここに独立したLLMを設定してください
    llm: ChatGLMLLM
    # plugins_func/functions以下のモジュールを選択してロードできます
    # システムは既に"handle_exit_intent（退出識別）"、"play_music（音楽再生）"プラグインをロードしています
    # 以下は、天気情報取得、ロール変更、ニュース情報取得プラグインのロード例です
    functions:
      - get_weather
      - get_news_from_newsnow
  function_call:
    # タイプは変更しないでください
    type: function_call
    # plugins_func/functions以下のモジュールを選択してロードできます
    # システムは既に"handle_exit_intent（退出識別）"、"play_music（音楽再生）"プラグインをロードしています
    # 以下は、天気情報取得、ロール変更、ニュース情報取得プラグインのロード例です
    functions:
      - change_role
      - get_weather
      - get_news_from_newsnow
      # play_musicはサーバー自体の音楽再生機能、hass_play_musicはHome Assistantを介した外部プログラムの音楽再生機能
      # play_musicとhass_play_musicのどちらかを使用してください
      - play_music
      #- hass_get_state
      #- hass_set_state
      #- hass_play_music

# 記憶設定
Memory:
  mem0ai:
    type: mem0ai
    # 1ヶ月あたり1000回の無料呼び出し
    api_key: 你的mem0ai api key
  nomem:
    # 記憶機能を使用しない
    type: nomem
  mem_local_short:
    # ローカル記憶機能
    type: mem_local_short
    # 記憶ストレージ用の独立した思考モデル
    # ここに設定しない場合は、selected_module.LLMのモデルが記憶ストレージの思考モデルとして使用されます
    # selected_module.LLMを使用したくない場合は、ここに独立したLLMを設定してください
    llm: ChatGLMLLM

# 音声認識設定
ASR:
  FunASR:
    type: fun_local
    model_dir: models/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx
    output_dir: tmp/
  FunASRServer:
    # 独立したFunASRサーバーを使用する
    # 以下のコマンドを実行してください
    # mkdir -p ./funasr-runtime-resources/models
    # sudo docker run -p 10096:10095 -it --privileged=true -v $PWD/funasr-runtime-resources/models:/workspace/models registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.12
    # 上記のコマンドを実行後、コンテナ内で以下のコマンドを実行してください
    # cd FunASR/runtime
    # nohup bash run_server_2pass.sh --download-model-dir /workspace/models --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx --model-dir damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst --itn-dir thuduj12/fst_itn_zh --hotword /workspace/models/hotwords.txt > log.txt 2>&1 &
    # 上記のコマンドを実行後、コンテナ内で以下のコマンドを実行してください
    # tail -f log.txt
    # 上記のコマンドを実行後、モデルがダウンロードされ、使用可能になります
    type: fun_server
    host: 127.0.0.1
    port: 10096
    output_dir: tmp/
  XunFeiASR:
    # 讯飞语音识别，需要自行申请
    type: xunfei
    appid: 你的appid
    api_secret: 你的api_secret
    api_key: 你的api_key
    output_dir: tmp/
  BaiduASR:
    # 百度语音识别，需要自行申请
    type: baidu
    appid: 你的appid
    api_key: 你的api_key
    secret_key: 你的secret_key
    dev_pid: 1537
    output_dir: tmp/

# 音声アクティビティ検出設定
VAD:
  SileroVAD:
    type: silero
    model_dir: models/snakers4_silero-vad
    min_silence_duration_ms: 200  # 如果说话停顿比较长，可以把这个值设置大一些

# LLM設定
LLM:
  # 所有openai类型均可以修改超参，以AliLLM为例
  # 当前支持的type为openai、dify、ollama，可自行适配
  AliLLM:
    type: openai
    api_base: https://dashscope.aliyuncs.com/compatible-mode/v1
    api_key: 你的api_key
    model_name: qwen-max
    temperature: 0.1
    max_tokens: 2000
  ChatGLMLLM:
    # 默认使用免费的ChatGLM-6B模型
    type: chatglm
    api_base: https://open.bigmodel.cn/api/paas/v3
    api_key: 你的api_key
    model_name: glm-3-turbo
    temperature: 0.1
    max_tokens: 2000
  DoubaoLLM:
    # 豆包大模型
    type: doubao
    api_base: https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation
    api_key: 你的api_key
    model_name: doubao-1-5-pro-32k-250115
    temperature: 0.1
    max_tokens: 2000
  DeepSeekLLM:
    # DeepSeek大模型
    type: deepseek
    api_base: https://api.deepseek.com/v1
    api_key: 你的api_key
    model_name: deepseek-chat
    temperature: 0.1
    max_tokens: 2000
  OllamaLLM:
    # 本地部署的ollama模型
    type: ollama
    api_base: http://127.0.0.1:11434
    model_name: qwen:7b
    temperature: 0.1
    max_tokens: 2000
  OpenAILLM:
    # OpenAI LLM
    type: openai
    api_base: https://api.openai.com/v1
    api_key: 你的api_key
    model_name: gpt-3.5-turbo
    temperature: 0.7
    max_tokens: 1500

# TTS設定
TTS:
  EdgeTTS:
    # 微软Edge TTS，免费使用
    type: edge
    voice: zh-CN-YunxiNeural
    output_dir: tmp/
  XunFeiTTS:
    # 讯飞语音合成，需要自行申请
    type: xunfei
    appid: 你的appid
    api_secret: 你的api_secret
    api_key: 你的api_key
    voice_name: aisjiuxu
    output_dir: tmp/
  BaiduTTS:
    # 百度语音合成，需要自行申请
    type: baidu
    appid: 你的appid
    api_key: 你的api_key
    secret_key: 你的secret_key
    voice_name: 0
    output_dir: tmp/

# 視覚言語大モデル設定
VLLM:
  ChatGLMVLLM:
    # 默认使用免费的ChatGLM-6B模型
    type: chatglm
    api_base: https://open.bigmodel.cn/api/paas/v3
    api_key: 你的api_key
    model_name: glm-4v
    temperature: 0.1
    max_tokens: 2000
  AliVLLM:
    type: openai
    api_base: https://dashscope.aliyuncs.com/compatible-mode/v1
    api_key: 你的api_key
    model_name: qwen-vl-plus
    temperature: 0.1
    max_tokens: 2000
  OllamaVLLM:
    # 本地部署的ollama模型
    type: ollama
    api_base: http://127.0.0.1:11434
    model_name: llava:7b
    temperature: 0.1
    max_tokens: 2000
