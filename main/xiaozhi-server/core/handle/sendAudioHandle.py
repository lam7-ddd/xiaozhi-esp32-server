import json
import asyncio
import time
from core.providers.tts.dto.dto import SentenceType
from core.utils.util import get_string_no_punctuation_or_emoji, analyze_emotion
from loguru import logger

TAG = __name__

emoji_map = {
    "neutral": "ğŸ˜¶",
    "happy": "ğŸ™‚",
    "laughing": "ğŸ˜†",
    "funny": "ğŸ˜‚",
    "sad": "ğŸ˜”",
    "angry": "ğŸ˜ ",
    "crying": "ğŸ˜­",
    "loving": "ğŸ˜",
    "embarrassed": "ğŸ˜³",
    "surprised": "ğŸ˜²",
    "shocked": "ğŸ˜±",
    "thinking": "ğŸ¤”",
    "winking": "ğŸ˜‰",
    "cool": "ğŸ˜",
    "relaxed": "ğŸ˜Œ",
    "delicious": "ğŸ¤¤",
    "kissy": "ğŸ˜˜",
    "confident": "ğŸ˜",
    "sleepy": "ğŸ˜´",
    "silly": "ğŸ˜œ",
    "confused": "ğŸ™„",
}


async def sendAudioMessage(conn, sentenceType, audios, text):
    # æ–‡ã®é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
    conn.logger.bind(tag=TAG).info(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡: {sentenceType}, {text}")
    if text is not None:
        emotion = analyze_emotion(text)
        emoji = emoji_map.get(emotion, "ğŸ™‚")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚¹ãƒã‚¤ãƒªãƒ¼ã‚’ä½¿ç”¨
        await conn.websocket.send(
            json.dumps(
                {
                    "type": "llm",
                    "text": emoji,
                    "emotion": emotion,
                    "session_id": conn.session_id,
                }
            )
        )
    pre_buffer = False
    if conn.tts.tts_audio_first_sentence and text is not None:
        conn.logger.bind(tag=TAG).info(f"æœ€åˆã®éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é€ä¿¡: {text}")
        conn.tts.tts_audio_first_sentence = False
        pre_buffer = True

    await send_tts_message(conn, "sentence_start", text)

    await sendAudio(conn, audios, pre_buffer)

    await send_tts_message(conn, "sentence_end", text)

    # çµ‚äº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ï¼ˆæœ€å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆï¼‰
    if conn.llm_finish_task and sentenceType == SentenceType.LAST:
        await send_tts_message(conn, "stop", None)
        conn.client_is_speaking = False
        if conn.close_after_chat:
            await conn.close()


# ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’å†ç”Ÿ
async def sendAudio(conn, audios, pre_buffer=True):
    if audios is None or len(audios) == 0:
        return
    # ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–
    frame_duration = 60  # ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰ã€Opusã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ä¸€è‡´
    start_time = time.perf_counter()
    play_position = 0
    last_reset_time = time.perf_counter()  # æœ€å¾Œã®ãƒªã‚»ãƒƒãƒˆæ™‚é–“ã‚’è¨˜éŒ²

    # æœ€åˆã®æ–‡ã®å ´åˆã®ã¿ãƒ—ãƒªãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
    if pre_buffer:
        pre_buffer_frames = min(3, len(audios))
        for i in range(pre_buffer_frames):
            await conn.websocket.send(audios[i])
        remaining_audios = audios[pre_buffer_frames:]
    else:
        remaining_audios = audios

    # æ®‹ã‚Šã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å†ç”Ÿ
    for opus_packet in remaining_audios:
        if conn.client_abort:
            break

        # éŸ³å£°ãŒãªã„çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        conn.last_activity_time = time.time() * 1000

        # æœŸå¾…ã•ã‚Œã‚‹é€ä¿¡æ™‚é–“ã‚’è¨ˆç®—
        expected_time = start_time + (play_position / 1000)
        current_time = time.perf_counter()
        delay = expected_time - current_time
        if delay > 0:
            await asyncio.sleep(delay)

        await conn.websocket.send(opus_packet)

        play_position += frame_duration


async def send_tts_message(conn, state, text=None):
    """TTSçŠ¶æ…‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
    message = {"type": "tts", "state": state, "session_id": conn.session_id}
    if text is not None:
        message["text"] = text

    # TTSå†ç”Ÿçµ‚äº†
    if state == "stop":
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéŸ³ã‚’å†ç”Ÿ
        tts_notify = conn.config.get("enable_stop_tts_notify", False)
        if tts_notify:
            stop_tts_notify_voice = conn.config.get(
                "stop_tts_notify_voice", "config/assets/tts_notify.mp3"
            )
            audios, _ = conn.tts.audio_to_opus_data(stop_tts_notify_voice)
            await sendAudio(conn, audios)
        # ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã®è©±ã™çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
        conn.clearSpeakStatus()

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
    await conn.websocket.send(json.dumps(message))


async def send_stt_message(conn, text):
    end_prompt_str = conn.config.get("end_prompt", {}).get("prompt")
    if end_prompt_str and end_prompt_str == text:
        await send_tts_message(conn, "start")
        return

    """STTçŠ¶æ…‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
    stt_text = get_string_no_punctuation_or_emoji(text)
    await conn.websocket.send(
        json.dumps({"type": "stt", "text": stt_text, "session_id": conn.session_id})
    )
    conn.client_is_speaking = True
    await send_tts_message(conn, "start")