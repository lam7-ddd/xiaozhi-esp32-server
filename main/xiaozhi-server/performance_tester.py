# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’WARNINGã«è¨­å®šã—ã€INFOãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚°ã‚’æŠ‘åˆ¶
logging.basicConfig(level=logging.WARNING)


class AsyncPerformanceTester:
    def __init__(self):
        self.config = load_config()
        self.test_sentences = self.config.get("module_test", {}).get(
            "test_sentences",
            [
                "ã“ã‚“ã«ã¡ã¯ã€è‡ªå·±ç´¹ä»‹ã‚’ã—ã¦ãã ã•ã„",
                "ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
                "é‡å­è¨ˆç®—ã®åŸºæœ¬åŸç†ã¨å¿œç”¨ã®å‰æ™¯ã‚’100å­—ã§æ¦‚èª¬ã—ã¦ãã ã•ã„",
            ],
        )

        self.test_wav_list = []
        self.wav_root = r"config/assets"
        for file_name in os.listdir(self.wav_root):
            file_path = os.path.join(self.wav_root, file_name)
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ300KBã‚ˆã‚Šå¤§ãã„ã‹ãƒã‚§ãƒƒã‚¯
            if os.path.getsize(file_path) > 300 * 1024:  # 300KB = 300 * 1024 bytes
                with open(file_path, "rb") as f:
                    self.test_wav_list.append(f.read())

        self.results = {"llm": {}, "tts": {}, "stt": {}, "combinations": []}

    async def _check_ollama_service(self, base_url: str, model_name: str) -> bool:
        """Ollamaã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’éåŒæœŸã§ãƒã‚§ãƒƒã‚¯"""
        async with aiohttp.ClientSession() as session:
            try:
                # ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                async with session.get(f"{base_url}/api/version") as response:
                    if response.status != 200:
                        print(f"ğŸš« Ollamaã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ãªã„ã‹ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„: {base_url}")
                        return False

                # ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                async with session.get(f"{base_url}/api/tags") as response:
                    if response.status == 200:
                        data = await response.json()
                        models = data.get("models", [])
                        if not any(model["name"] == model_name for model in models):
                            print(
                                f"ğŸš« Ollamaãƒ¢ãƒ‡ãƒ« {model_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãš ollama pull {model_name} ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
                            )
                            return False
                    else:
                        print(f"ğŸš« Ollamaãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“")
                        return False
                return True
            except Exception as e:
                print(f"ğŸš« Ollamaã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“: {str(e)}")
                return False

    async def _test_tts(self, tts_name: str, config: Dict) -> Dict:
        """å˜ä¸€ã®TTSã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’éåŒæœŸã§ãƒ†ã‚¹ãƒˆ"""
        try:
            logging.getLogger("core.providers.tts.base").setLevel(logging.WARNING)

            token_fields = ["access_token", "api_key", "token"]
            if any(
                field in config
                and any(x in config[field] for x in ["ã‚ãªãŸã®", "placeholder"])
                for field in token_fields
            ):
                print(f"â­ï¸  TTS {tts_name} ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³/ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return {"name": tts_name, "type": "tts", "errors": 1}

            module_type = config.get("type", tts_name)
            tts = create_tts_instance(module_type, config, delete_audio_file=True)

            print(f"ğŸµ TTS {tts_name} ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™")

            tmp_file = tts.generate_filename()
            await tts.text_to_speak("ãƒ†ã‚¹ãƒˆæ¥ç¶š", tmp_file)

            if not tmp_file or not os.path.exists(tmp_file):
                print(f"âŒ {tts_name} ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
                return {"name": tts_name, "type": "tts", "errors": 1}

            total_time = 0
            test_count = len(self.test_sentences[:2])

            for i, sentence in enumerate(self.test_sentences[:2], 1):
                start = time.time()
                tmp_file = tts.generate_filename()
                await tts.text_to_speak(sentence, tmp_file)
                duration = time.time() - start
                total_time += duration

                if tmp_file and os.path.exists(tmp_file):
                    print(f"âœ“ {tts_name} [{i}/{test_count}]")
                else:
                    print(f"âœ— {tts_name} [{i}/{test_count}]")
                    return {"name": tts_name, "type": "tts", "errors": 1}

            return {
                "name": tts_name,
                "type": "tts",
                "avg_time": total_time / test_count,
                "errors": 0,
            }

        except Exception as e:
            print(f"âš ï¸ {tts_name} ã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return {"name": tts_name, "type": "tts", "errors": 1}

    async def _test_stt(self, stt_name: str, config: Dict) -> Dict:
        """å˜ä¸€ã®STTã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’éåŒæœŸã§ãƒ†ã‚¹ãƒˆ"""
        try:
            logging.getLogger("core.providers.asr.base").setLevel(logging.WARNING)
            token_fields = ["access_token", "api_key", "token"]
            if any(
                field in config
                and any(x in config[field] for x in ["ã‚ãªãŸã®", "placeholder"])
                for field in token_fields
            ):
                print(f"â­ï¸  STT {stt_name} ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³/ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return {"name": stt_name, "type": "stt", "errors": 1}

            module_type = config.get("type", stt_name)
            stt = create_stt_instance(module_type, config, delete_audio_file=True)
            stt.audio_format = "pcm"

            print(f"ğŸµ STT {stt_name} ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™")

            text, _ = await stt.speech_to_text(
                [self.test_wav_list[0]], "1", stt.audio_format
            )

            if text is None:
                print(f"âŒ {stt_name} ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
                return {"name": stt_name, "type": "stt", "errors": 1}

            total_time = 0
            test_count = len(self.test_wav_list)

            for i, sentence in enumerate(self.test_wav_list, 1):
                start = time.time()
                text, _ = await stt.speech_to_text([sentence], "1", stt.audio_format)
                duration = time.time() - start
                total_time += duration

                if text:
                    print(f"âœ“ {stt_name} [{i}/{test_count}]")
                else:
                    print(f"âœ— {stt_name} [{i}/{test_count}]")
                    return {"name": stt_name, "type": "stt", "errors": 1}

            return {
                "name": stt_name,
                "type": "stt",
                "avg_time": total_time / test_count,
                "errors": 0,
            }

        except Exception as e:
            print(f"âš ï¸ {stt_name} ã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return {"name": stt_name, "type": "stt", "errors": 1}

    async def _test_llm(self, llm_name: str, config: Dict) -> Dict:
        """å˜ä¸€ã®LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’éåŒæœŸã§ãƒ†ã‚¹ãƒˆ"""
        try:
            # Ollamaã®å ´åˆã€APIã‚­ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã›ãšã«ã‚µãƒ¼ãƒ“ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
            if llm_name == "Ollama":
                base_url = config.get("base_url", "http://localhost:11434")
                model_name = config.get("model_name")
                if not model_name:
                    print(f"ğŸš« Ollamaã®ãƒ¢ãƒ‡ãƒ«åãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    return {"name": llm_name, "type": "llm", "errors": 1}

                if not await self._check_ollama_service(base_url, model_name):
                    return {"name": llm_name, "type": "llm", "errors": 1}
            else:
                if "api_key" in config and any(
                    x in config["api_key"] for x in ["ã‚ãªãŸã®", "placeholder", "sk-xxx"]
                ):
                    print(f"ğŸš« LLM {llm_name} ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                    return {"name": llm_name, "type": "llm", "errors": 1}

            # å®Ÿéš›ã®ã‚¿ã‚¤ãƒ—ï¼ˆå¤ã„è¨­å®šã¨ã®äº’æ›æ€§ã®ãŸã‚ï¼‰
            module_type = config.get("type", llm_name)
            llm = create_llm_instance(module_type, config)

            # UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
            test_sentences = [
                s.encode("utf-8").decode("utf-8") for s in self.test_sentences
            ]

            # å„æ–‡ã®ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
            sentence_tasks = []
            for sentence in test_sentences:
                sentence_tasks.append(
                    self._test_single_sentence(llm_name, llm, sentence)
                )

            # å…¨æ–‡ã®ãƒ†ã‚¹ãƒˆã‚’ä¸¦è¡Œå®Ÿè¡Œ
            sentence_results = await asyncio.gather(*sentence_tasks)

            # çµæœã‚’å‡¦ç†
            valid_results = [r for r in sentence_results if r is not None]
            if not valid_results:
                print(f"âš ï¸  {llm_name} ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è¨­å®šãŒé–“é•ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                return {"name": llm_name, "type": "llm", "errors": 1}

            first_token_times = [r["first_token_time"] for r in valid_results]
            response_times = [r["response_time"] for r in valid_results]

            # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            mean = statistics.mean(response_times)
            stdev = statistics.stdev(response_times) if len(response_times) > 1 else 0
            filtered_times = [t for t in response_times if t <= mean + 3 * stdev]

            if len(filtered_times) < len(test_sentences) * 0.5:
                print(f"âš ï¸  {llm_name} ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒä¸å®‰å®šã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                return {"name": llm_name, "type": "llm", "errors": 1}

            return {
                "name": llm_name,
                "type": "llm",
                "avg_response": sum(response_times) / len(response_times),
                "avg_first_token": sum(first_token_times) / len(first_token_times),
                "std_first_token": (
                    statistics.stdev(first_token_times)
                    if len(first_token_times) > 1
                    else 0
                ),
                "std_response": (
                    statistics.stdev(response_times) if len(response_times) > 1 else 0
                ),
                "errors": 0,
            }
        except Exception as e:
            print(f"LLM {llm_name} ã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return {"name": llm_name, "type": "llm", "errors": 1}

    async def _test_single_sentence(self, llm_name: str, llm, sentence: str) -> Dict:
        """å˜ä¸€ã®æ–‡ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ"""
        try:
            print(f"ğŸ“ {llm_name} ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™: {sentence[:20]}...")
            sentence_start = time.time()
            first_token_received = False
            first_token_time = None

            async def process_response():
                nonlocal first_token_received, first_token_time
                for chunk in llm.response(
                    "perf_test", [{"role": "user", "content": sentence}]
                ):
                    if not first_token_received and chunk.strip() != "":
                        first_token_time = time.time() - sentence_start
                        first_token_received = True
                        print(f"âœ“ {llm_name} ã®æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³: {first_token_time:.3f}ç§’")
                    yield chunk

            response_chunks = []
            async for chunk in process_response():
                response_chunks.append(chunk)

            response_time = time.time() - sentence_start
            print(f"âœ“ {llm_name} ã®å¿œç­”å®Œäº†: {response_time:.3f}ç§’")

            if first_token_time is None:
                first_token_time = (
                    response_time  # æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã€å¿œç­”æ™‚é–“ã‚’ä½¿ç”¨
                )

            return {
                "name": llm_name,
                "type": "llm",
                "first_token_time": first_token_time,
                "response_time": response_time,
            }
        except Exception as e:
            print(f"âš ï¸ {llm_name} ã®æ–‡ã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return None

    def _generate_combinations(self):
        """ãƒ™ã‚¹ãƒˆãªçµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆ"""
        valid_llms = [
            k
            for k, v in self.results["llm"].items()
            if v["errors"] == 0 and v["avg_first_token"] >= 0.05
        ]
        valid_tts = [k for k, v in self.results["tts"].items() if v["errors"] == 0]
        valid_stt = [k for k, v in self.results["stt"].items() if v["errors"] == 0]

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å€¤ã‚’å–å¾—
        min_first_token = (
            min([self.results["llm"][llm]["avg_first_token"] for llm in valid_llms])
            if valid_llms
            else 1
        )
        min_tts_time = (
            min([self.results["tts"][tts]["avg_time"] for tts in valid_tts])
            if valid_tts
            else 1
        )
        min_stt_time = (
            min([self.results["stt"][stt]["avg_time"] for stt in valid_stt])
            if valid_stt
            else 1
        )

        for llm in valid_llms:
            for tts in valid_tts:
                for stt in valid_stt:
                    # ç›¸å¯¾çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆå°ã•ã„æ–¹ãŒè‰¯ã„ï¼‰
                    llm_score = (
                        self.results["llm"][llm]["avg_first_token"] / min_first_token
                    )
                    tts_score = self.results["tts"][tts]["avg_time"] / min_tts_time
                    stt_score = self.results["stt"][stt]["avg_time"] / min_stt_time

                    # å®‰å®šæ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ¨™æº–åå·®/å¹³å‡å€¤ã€å°ã•ã„æ–¹ãŒå®‰å®šï¼‰
                    llm_stability = (
                        self.results["llm"][llm]["std_first_token"]
                        / self.results["llm"][llm]["avg_first_token"]
                    )

                    # ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å®‰å®šæ€§ã‚’è€ƒæ…®ï¼‰
                    # LLMã‚¹ã‚³ã‚¢ï¼šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é‡ã¿ï¼ˆ70ï¼…ï¼‰+ å®‰å®šæ€§ã®é‡ã¿ï¼ˆ30ï¼…ï¼‰
                    llm_final_score = llm_score * 0.7 + llm_stability * 0.3

                    # ç·ã‚¹ã‚³ã‚¢ = LLMã‚¹ã‚³ã‚¢ï¼ˆ70ï¼…ï¼‰+ TTSã‚¹ã‚³ã‚¢ï¼ˆ30ï¼…ï¼‰+ STTã‚¹ã‚³ã‚¢ï¼ˆ30ï¼…ï¼‰
                    total_score = (
                        llm_final_score * 0.7 + tts_score * 0.3 + stt_score * 0.3
                    )

                    self.results["combinations"].append(
                        {
                            "llm": llm,
                            "tts": tts,
                            "stt": stt,
                            "score": total_score,
                            "details": {
                                "llm_first_token": self.results["llm"][llm][
                                    "avg_first_token"
                                ],
                                "llm_stability": llm_stability,
                                "tts_time": self.results["tts"][tts]["avg_time"],
                                "stt_time": self.results["stt"][stt]["avg_time"],
                            },
                        }
                    )

        # ã‚¹ã‚³ã‚¢ãŒå°ã•ã„æ–¹ãŒè‰¯ã„
        self.results["combinations"].sort(key=lambda x: x["score"])

    def _print_results(self):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’å‡ºåŠ›"""
        llm_table = []
        for name, data in self.results["llm"].items():
            if data["errors"] == 0:
                stability = data["std_first_token"] / data["avg_first_token"]
                llm_table.append(
                    [
                        name,  # å¹…ã‚’å›ºå®šã—ãªã„ã€tabulateãŒè‡ªå‹•çš„ã«èª¿æ•´
                        f"{data['avg_first_token']:.3f}ç§’",
                        f"{data['avg_response']:.3f}ç§’",
                        f"{stability:.3f}",
                    ]
                )

        if llm_table:
            print("\nLLM ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°:\n")
            print(
                tabulate(
                    llm_table,
                    headers=["ãƒ¢ãƒ‡ãƒ«å", "æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ™‚é–“", "ç·æ™‚é–“", "å®‰å®šæ€§"],
                    tablefmt="github",
                    colalign=("left", "right", "right", "right"),
                    disable_numparse=True,
                )
            )
        else:
            print("\nâš ï¸ ãƒ†ã‚¹ãƒˆå¯èƒ½ãªLLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        tts_table = []
        for name, data in self.results["tts"].items():
            if data["errors"] == 0:
                tts_table.append([name, f"{data['avg_time']:.3f}ç§’"])  # å¹…ã‚’å›ºå®šã—ãªã„

        if tts_table:
            print("\nTTS ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°:\n")
            print(
                tabulate(
                    tts_table,
                    headers=["ãƒ¢ãƒ‡ãƒ«å", "åˆæˆæ™‚é–“"],
                    tablefmt="github",
                    colalign=("left", "right"),
                    disable_numparse=True,
                )
            )
        else:
            print("\nâš ï¸ ãƒ†ã‚¹ãƒˆå¯èƒ½ãªTTSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        stt_table = []
        for name, data in self.results["stt"].items():
            if data["errors"] == 0:
                stt_table.append([name, f"{data['avg_time']:.3f}ç§’"])  # å¹…ã‚’å›ºå®šã—ãªã„

        if stt_table:
            print("\nSTT ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°:\n")
            print(
                tabulate(
                    stt_table,
                    headers=["ãƒ¢ãƒ‡ãƒ«å", "åˆæˆæ™‚é–“"],
                    tablefmt="github",
                    colalign=("left", "right"),
                    disable_numparse=True,
                )
            )
        else:
            print("\nâš ï¸ ãƒ†ã‚¹ãƒˆå¯èƒ½ãªSTTãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        if self.results["combinations"]:
            print("\næ¨å¥¨è¨­å®šã®çµ„ã¿åˆã‚ã› (ã‚¹ã‚³ã‚¢ãŒå°ã•ã„æ–¹ãŒè‰¯ã„):\n")
            combo_table = []
            for combo in self.results["combinations"][:]:
                combo_table.append(
                    [
                        f"{combo['llm']} + {combo['tts']} + {combo['stt']}",  # å¹…ã‚’å›ºå®šã—ãªã„
                        f"{combo['score']:.3f}",
                        f"{combo['details']['llm_first_token']:.3f}ç§’",
                        f"{combo['details']['llm_stability']:.3f}",
                        f"{combo['details']['tts_time']:.3f}ç§’",
                        f"{combo['details']['stt_time']:.3f}ç§’",
                    ]
                )

            print(
                tabulate(
                    combo_table,
                    headers=[
                        "çµ„ã¿åˆã‚ã›",
                        "ç·åˆã‚¹ã‚³ã‚¢",
                        "LLMæœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ™‚é–“",
                        "å®‰å®šæ€§",
                        "TTSåˆæˆæ™‚é–“",
                        "STTåˆæˆæ™‚é–“",
                    ],
                    tablefmt="github",
                    colalign=("left", "right", "right", "right", "right", "right"),
                    disable_numparse=True,
                )
            )
        else:
            print("\nâš ï¸ æ¨å¥¨è¨­å®šã®çµ„ã¿åˆã‚ã›ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    def _process_results(self, all_results):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’å‡¦ç†"""
        for result in all_results:
            if result["errors"] == 0:
                if result["type"] == "llm":
                    self.results["llm"][result["name"]] = result
                elif result["type"] == "tts":
                    self.results["tts"][result["name"]] = result
                elif result["type"] == "stt":
                    self.results["stt"][result["name"]] = result
                else:
                    pass

    async def run(self):
        """å…¨é‡ã®éåŒæœŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("ğŸ” åˆ©ç”¨å¯èƒ½ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™...")

        # å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        all_tasks = []

        # LLMãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯
        if self.config.get("LLM") is not None:
            for llm_name, config in self.config.get("LLM", {}).items():
                # è¨­å®šã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                if llm_name == "CozeLLM":
                    if any(x in config.get("bot_id", "") for x in ["ã‚ãªãŸã®"]) or any(
                        x in config.get("user_id", "") for x in ["ã‚ãªãŸã®"]
                    ):
                        print(f"â­ï¸  LLM {llm_name} ã®bot_id/user_idãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                        continue
                elif "api_key" in config and any(
                    x in config["api_key"] for x in ["ã‚ãªãŸã®", "placeholder", "sk-xxx"]
                ):
                    print(f"â­ï¸  LLM {llm_name} ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                    continue

                # Ollamaã®å ´åˆã€ã‚µãƒ¼ãƒ“ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                if llm_name == "Ollama":
                    base_url = config.get("base_url", "http://localhost:11434")
                    model_name = config.get("model_name")
                    if not model_name:
                        print(f"ğŸš« Ollamaã®ãƒ¢ãƒ‡ãƒ«åãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                        continue

                    if not await self._check_ollama_service(base_url, model_name):
                        continue

                print(f"ğŸ“‹ LLMãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ : {llm_name}")
                module_type = config.get("type", llm_name)
                llm = create_llm_instance(module_type, config)

                # å„æ–‡ã®ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
                for sentence in self.test_sentences:
                    sentence = sentence.encode("utf-8").decode("utf-8")
                    all_tasks.append(
                        self._test_single_sentence(llm_name, llm, sentence)
                    )

        # TTSãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯
        if self.config.get("TTS") is not None:
            for tts_name, config in self.config.get("TTS", {}).items():
                token_fields = ["access_token", "api_key", "token"]
                if any(
                    field in config
                    and any(x in config[field] for x in ["ã‚ãªãŸã®", "placeholder"])
                    for field in token_fields
                ):
                    print(f"â­ï¸  TTS {tts_name} ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³/ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                    continue
                print(f"ğŸµ TTSãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ : {tts_name}")
                all_tasks.append(self._test_tts(tts_name, config))

        # STTãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯
        if len(self.test_wav_list) >= 1:
            if self.config.get("ASR") is not None:
                for stt_name, config in self.config.get("ASR", {}).items():
                    token_fields = ["access_token", "api_key", "token"]
                    if any(
                        field in config
                        and any(x in config[field] for x in ["ã‚ãªãŸã®", "placeholder"])
                        for field in token_fields
                    ):
                        print(f"â­ï¸  ASR {stt_name} ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³/ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                        continue
                    print(f"ğŸµ ASRãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ : {stt_name}")
                    all_tasks.append(self._test_stt(stt_name, config))
        else:
            print(f"\nâš ï¸  {self.wav_root} ãƒ‘ã‚¹ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚STTãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

        print(
            f"\nâœ… {len([t for t in all_tasks if 'test_single_sentence' in str(t)]) / len(self.test_sentences):.0f} å€‹ã®åˆ©ç”¨å¯èƒ½ãªLLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ"
        )
        print(
            f"âœ… {len([t for t in all_tasks if '_test_tts' in str(t)])} å€‹ã®åˆ©ç”¨å¯èƒ½ãªTTSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ"
        )
        print(
            f"âœ… {len([t for t in all_tasks if '_test_stt' in str(t)])} å€‹ã®åˆ©ç”¨å¯èƒ½ãªSTTãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ"
        )
        print("\nâ³ å…¨ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™...\n")

        # å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’ä¸¦è¡Œå®Ÿè¡Œ
        all_results = await asyncio.gather(*all_tasks, return_exceptions=True)

        # LLMçµæœã‚’å‡¦ç†
        llm_results = {}
        for result in [
            r
            for r in all_results
            if r and isinstance(r, dict) and r.get("type") == "llm"
        ]:
            llm_name = result["name"]
            if llm_name not in llm_results:
                llm_results[llm_name] = {
                    "name": llm_name,
                    "type": "llm",
                    "first_token_times": [],
                    "response_times": [],
                    "errors": 0,
                }
            llm_results[llm_name]["first_token_times"].append(
                result["first_token_time"]
            )
            llm_results[llm_name]["response_times"].append(result["response_time"])

        # LLMã®å¹³å‡å€¤ã¨æ¨™æº–åå·®ã‚’è¨ˆç®—
        for llm_name, data in llm_results.items():
            if len(data["first_token_times"]) >= len(self.test_sentences) * 0.5:
                self.results["llm"][llm_name] = {
                    "name": llm_name,
                    "type": "llm",
                    "avg_response": sum(data["response_times"])
                    / len(data["response_times"]),
                    "avg_first_token": sum(data["first_token_times"])
                    / len(data["first_token_times"]),
                    "std_first_token": (
                        statistics.stdev(data["first_token_times"])
                        if len(data["first_token_times"]) > 1
                        else 0
                    ),
                    "std_response": (
                        statistics.stdev(data["response_times"])
                        if len(data["response_times"]) > 1
                        else 0
                    ),
                    "errors": 0,
                }

        # TTSçµæœã‚’å‡¦ç†
        for result in [
            r
            for r in all_results
            if r and isinstance(r, dict) and r.get("type") == "tts"
        ]:
            if result["errors"] == 0:
                self.results["tts"][result["name"]] = result

        # STTçµæœã‚’å‡¦ç†
        for result in [
            r
            for r in all_results
            if r and isinstance(r, dict) and r.get("type") == "stt"
        ]:
            if result["errors"] == 0:
                self.results["stt"][result["name"]] = result

        # çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆã—ã€çµæœã‚’å‡ºåŠ›
        print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        self._generate_combinations()
        self._print_results()


async def main():
    tester = AsyncPerformanceTester()
    await tester.run()


if __name__ == "__main__":
    asyncio.run(main())
